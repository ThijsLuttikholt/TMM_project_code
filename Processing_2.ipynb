{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text and multimedia mining: project RQ2 file\n",
    "\n",
    "In this file, the processing of all the data for research question 2 will be done. This includes evaluations for the data that were obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_json('RQ2_dataset.json.gz', lines=True, compression='gzip')\n",
    "data2 = data2.groupby(['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18892\n"
     ]
    }
   ],
   "source": [
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For question 2, we need two groups, spoiler and non-spoiler.\n",
    "#For each item, we need the length, and the amount of emotion-like words. \n",
    "emotion_words = ['happiness', 'happy', 'sadness', 'sad', 'fear', 'scared', \n",
    "                 'disgust', 'disgusted', 'anger', 'angry', 'surprise', 'surprised']\n",
    "data2_processed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_intersections(list1, list2):\n",
    "    intersections = [word for word in list1 if word in list2] \n",
    "    return len(intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "finished the calculation\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for name, group in data2:\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    amount_spoiler = 0\n",
    "    amount_nonspoiler = 0\n",
    "    length_spoiler = 0\n",
    "    length_nonspoiler = 0\n",
    "    freq_emotion_spoiler = 0\n",
    "    freq_emotion_nonspoiler = 0\n",
    "    for index,item in enumerate(group['review_sentences']):\n",
    "        for item2 in item:\n",
    "            subbed_item = re.sub('[,.!?-]','', item2[1])\n",
    "            subbed_item2 = subbed_item.lower().split()\n",
    "            cur_length = len(subbed_item2)\n",
    "            num_emotion = num_intersections(subbed_item2, emotion_words)\n",
    "            if int(item2[0]) == 0:\n",
    "                length_nonspoiler += cur_length\n",
    "                amount_nonspoiler += 1\n",
    "                freq_emotion_nonspoiler += num_emotion\n",
    "            else:\n",
    "                length_spoiler += cur_length\n",
    "                amount_spoiler += 1\n",
    "                freq_emotion_spoiler += num_emotion\n",
    "    i += 1\n",
    "    if amount_spoiler > 0 and amount_nonspoiler > 0 and length_spoiler > 0 and length_nonspoiler > 0:\n",
    "        data2_processed.append([length_spoiler/amount_spoiler, freq_emotion_spoiler/length_spoiler, \n",
    "                     length_nonspoiler/amount_nonspoiler, freq_emotion_nonspoiler/length_nonspoiler])\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            #if length > 0:\n",
    "            #    if int(item2[0]) == 0:\n",
    "            #        data_nonspoiler.append([length, num_emotion/length])\n",
    "            #    else:\n",
    "            #        data_spoilers.append([length, num_emotion/length])\n",
    "            #else:\n",
    "            #    if int(item2[0]) == 0:\n",
    "            #        data_nonspoiler.append([0, 0])\n",
    "            #    else:\n",
    "            #        data_spoilers.append([0, 0])\n",
    "\n",
    "print('finished the calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "data2_processed2 = np.array(data2_processed)\n",
    "np.save('processed_rq2.npy', data2_processed2)\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.064812039108975\n",
      "0.0023046379740511175\n",
      "15.130683889986425\n",
      "0.0013755991128588732\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data2_processed2[:,0]))\n",
    "print(np.mean(data2_processed2[:,1]))\n",
    "print(np.mean(data2_processed2[:,2]))\n",
    "print(np.mean(data2_processed2[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
